{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import *\n",
    "import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import model\n",
    "import tool\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = Random()\n",
    "a.seed(1)\n",
    "\n",
    "def setting(data):\n",
    "    vocab_size, word_emb_size = data['embedding'].shape\n",
    "    sample_num, max_time = data['x_ex'].shape\n",
    "    test_num = data['x_em'].shape[0]\n",
    "    s_cnum = np.unique(data['y_ex']).shape[0]\n",
    "    u_cnum = np.unique(data['y_em']).shape[0]\n",
    "\n",
    "    FLAGS = tf.compat.v1.flags.FLAGS\n",
    "    tf.compat.v1.flags.DEFINE_float(\"keep_prob\", 0.8, \"embedding dropout keep rate\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"hidden_size\", 32, \"embedding vector size\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"batch_size\", 64, \"vocab size of word vectors\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"num_epochs\", 100, \"num of epochs\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"vocab_size\", vocab_size, \"vocab size of word vectors\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"max_time\", max_time, \"max number of words in one sentesnce\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"sample_num\", sample_num, \"sample number of training data\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"test_num\", test_num, \"number of test data\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"s_cnum\", s_cnum, \"seen class num\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"u_cnum\", u_cnum, \"unseen class num\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"word_emb_size\", word_emb_size, \"embedding size of word vectors\")\n",
    "    tf.compat.v1.flags.DEFINE_string(\"ckpt_dir\", './saved_models/' , \"check point dir\")\n",
    "    tf.compat.v1.flags.DEFINE_boolean(\"use_embedding\", True, \"whether to use embedding or not.\")\n",
    "    tf.compat.v1.flags.DEFINE_float(\"learning_rate\", 0.001, \"learning rate\")\n",
    "    tf.compat.v1.flags.DEFINE_float(\"sim_scale\", 4, \"sim scale\")\n",
    "    tf.compat.v1.flags.DEFINE_float(\"margin\", 1.0, \"ranking loss margin\")\n",
    "    tf.compat.v1.flags.DEFINE_float(\"alpha\", 0.0001, \"coefficient for self attention loss\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"num_routing\", 2, \"capsule routing num\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"output_atoms\", 10, \"capsule output atoms\")\n",
    "    tf.compat.v1.flags.DEFINE_boolean(\"save_model\", False, \"save model to disk\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"d_a\", 20, \"self attention weight hidden units number\")\n",
    "    tf.compat.v1.flags.DEFINE_integer(\"r\", 3, \"self attention weight hops\")\n",
    "    return FLAGS\n",
    "\n",
    "def get_sim(data):\n",
    "    # get unseen and seen categories similarity\n",
    "    ex = normalize(data['ex_vec'])\n",
    "    em = normalize(data['em_vec'])\n",
    "    sim = tool.compute_label_sim(em, ex, FLAGS.sim_scale)\n",
    "    return sim\n",
    "\n",
    "def evaluate_zsl(data, FLAGS, sess):\n",
    "    # zero-shot testing state\n",
    "    # seen votes shape (110, 2, 34, 10)\n",
    "    x_em = data['x_em']\n",
    "    y_em_id = data['y_em']\n",
    "    em_len = data['em_len']\n",
    "    #em_intent = data['em_intent']\n",
    "\n",
    "    # get unseen and seen categories similarity\n",
    "    # sim shape (8, 34)\n",
    "    sim_ori = get_sim(data)\n",
    "    \n",
    "    # origin_sim, new_sim\n",
    "    # similarity = 0.5(1+1/cak)origin_sim+0.5(1-1/k)new_sim\n",
    "\n",
    "    #sim_ori = data['em_logits']\n",
    "\n",
    "    total_unseen_pred = np.array([], dtype=np.int64)\n",
    "\n",
    "    batch_size  = FLAGS.test_num\n",
    "    test_batch = int(math.ceil(FLAGS.test_num / float(batch_size)))\n",
    "    #test_batch = int(math.ceil(FLAGS.test_num / float(FLAGS.batch_size)))\n",
    "    for i in range(test_batch):\n",
    "        begin_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, FLAGS.test_num)\n",
    "        batch_te = x_em[begin_index : end_index]\n",
    "        batch_id = y_em_id[begin_index : end_index]\n",
    "        batch_len = em_len[begin_index : end_index]\n",
    "\n",
    "        [attentions, seen_logits, seen_votes, seen_weights_c] = sess.run([\n",
    "            lstm.attention, lstm.logits, lstm.votes, lstm.weights_c],\n",
    "            feed_dict={lstm.input_x: batch_te, lstm.s_len: batch_len})\n",
    "\n",
    "        sim = tf.expand_dims(sim_ori, [0])\n",
    "        sim = tf.tile(sim, [seen_votes.shape[1],1,1])\n",
    "        sim = tf.expand_dims(sim, [0])\n",
    "        sim = tf.tile(sim, [seen_votes.shape[0],1,1,1])\n",
    "        seen_weights_c = np.tile(np.expand_dims(seen_weights_c, -1), [1, 1, 1, FLAGS.output_atoms])\n",
    "        mul = np.multiply(seen_votes, seen_weights_c)\n",
    "\n",
    "        # compute unseen features \n",
    "        # unseen votes shape (110, 2, 8, 10)\n",
    "        unseen_votes = tf.matmul(sim, mul)\n",
    "\n",
    "        # routing unseen classes\n",
    "        u_activations, u_weights_c = update_unseen_routing(unseen_votes, FLAGS, 3)\n",
    "        unseen_logits = tf.norm(u_activations, axis=-1)\n",
    "        te_votes, te_logits, te_weights, te_activations = sess.run([\n",
    "            unseen_votes, unseen_logits, u_weights_c, u_activations])\n",
    "\n",
    "        te_batch_pred = np.argmax(te_logits, 1)\n",
    "        total_unseen_pred = np.concatenate((total_unseen_pred, te_batch_pred))\n",
    "\n",
    "    print (\"Zero-shot Intent Detection Results [INTENTCAPSNET-ZSL]\")\n",
    "    acc = accuracy_score(y_em_id, total_unseen_pred)\n",
    "    print (classification_report(y_em_id, total_unseen_pred, digits=4))\n",
    "    return acc\n",
    "\n",
    "def generate_batch(n, batch_size):\n",
    "    batch_index = a.sample(range(n), batch_size)\n",
    "    return batch_index\n",
    "\n",
    "def assign_pretrained_word_embedding(sess, data, textRNN):\n",
    "    print(\"using pre-trained word emebedding.begin...\")\n",
    "    embedding = data['embedding']\n",
    "\n",
    "    word_embedding = tf.constant(embedding, dtype=tf.float32)  # convert to tensor\n",
    "    t_assign_embedding = tf.compat.v1.assign(textRNN.Embedding,word_embedding)  # assign this value to our embedding variables of our model.\n",
    "    sess.run(t_assign_embedding)\n",
    "    print(\"using pre-trained word emebedding.ended...\")\n",
    "\n",
    "def squash(input_tensor):\n",
    "    norm = tf.norm(input_tensor, axis=2, keepdims=True)\n",
    "    norm_squared = norm * norm\n",
    "    return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n",
    "\n",
    "def update_unseen_routing(votes, FLAGS, num_routing=3):\n",
    "    votes_t_shape = [3, 0, 1, 2]\n",
    "    r_t_shape = [1, 2, 3, 0]\n",
    "    votes_trans = tf.transpose(votes, votes_t_shape)\n",
    "    num_dims = 4\n",
    "    input_dim = FLAGS.r\n",
    "    output_dim = FLAGS.u_cnum\n",
    "    input_shape = tf.shape(votes)\n",
    "    logit_shape = tf.stack([input_shape[0], input_dim, output_dim])\n",
    "\n",
    "    def _body(i, logits, activations, route):\n",
    "        route = tf.nn.softmax(logits)\n",
    "        preactivate_unrolled = route * votes_trans\n",
    "        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n",
    "        preactivate = tf.reduce_sum(preact_trans, axis=1)\n",
    "        activation = squash(preactivate)\n",
    "        activations = activations.write(i, activation)\n",
    "\n",
    "        act_3d = tf.expand_dims(activation, 1)\n",
    "        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n",
    "        tile_shape[1] = input_dim\n",
    "        act_replicated = tf.tile(act_3d, tile_shape)\n",
    "        distances = tf.reduce_sum(votes * act_replicated, axis=3)\n",
    "        logits += distances\n",
    "        return (i + 1, logits, activations, route)\n",
    "\n",
    "    activations = tf.TensorArray(\n",
    "        dtype=tf.float32, size=num_routing, clear_after_read=False)\n",
    "    logits = tf.fill(logit_shape, 0.0)\n",
    "    i = tf.constant(0, dtype=tf.int32)\n",
    "    route = tf.compat.v1.math.softmax(logits, dim=2)\n",
    "    _, logits, activations, route = tf.while_loop(\n",
    "        lambda i, logits, activations, route: i < num_routing,\n",
    "        _body,\n",
    "        loop_vars=[i, logits, activations, route],\n",
    "        swap_memory=True)\n",
    "\n",
    "    return activations.read(num_routing - 1), route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start Dataset Reading.]\n",
      "[Load Word2Vec model.]\n",
      "[Load normalized word embedding.]\n",
      "[Preprocess labels.]\n",
      "[Complete Dataset Reading.]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # load data\n",
    "    data = input_data.read_datasets()\n",
    "\n",
    "    embedding = data['embedding']\n",
    "\n",
    "    x_ex = data['x_ex']\n",
    "    y_ex_id = data['y_ex']\n",
    "    ex_len = data['ex_len']\n",
    "    y_idx = data['ex_label']\n",
    "\n",
    "    x_em = data['x_em']\n",
    "    y_em_id = data['y_em']\n",
    "    em_len = data['em_len']\n",
    "\n",
    "    label_em=data['label_em']\n",
    "    label_em_len=data['label_em_len']\n",
    "\n",
    "    # load settings\n",
    "    FLAGS = setting(data)\n",
    "\n",
    "    caps_train_loss=[]\n",
    "    caps_train_acc=[]\n",
    "    \n",
    "    caps_val_loss=[]\n",
    "    caps_val_acc=[]\n",
    "    \n",
    "    zsl_acc=[]\n",
    "\n",
    "    # start\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    config=tf.compat.v1.ConfigProto()\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "\n",
    "        # Instantiate Model\n",
    "        lstm = model.lstm_model(FLAGS)\n",
    "\n",
    "        if os.path.exists(FLAGS.ckpt_dir):\n",
    "            print(\"Restoring Variables from Checkpoint for rnn model.\")\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            saver.restore(sess,tf.train.latest_checkpoint(FLAGS.ckpt_dir))\n",
    "        else:\n",
    "            print('Initializing Variables')\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "            if FLAGS.use_embedding: #load pre-trained word embedding\n",
    "                assign_pretrained_word_embedding(sess, data, lstm)\n",
    "\n",
    "        xex_train, xex_test, _, yex_test, ex_len_train, ex_len_test, y_idx_train, y_idx_test = train_test_split(x_ex, y_ex_id, ex_len, y_idx, test_size=0.33, shuffle=False)\n",
    "        \n",
    "        best_caps_acc = 0\n",
    "        best_zsl_acc = 0\n",
    "        var_saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "            # training\n",
    "            total_batch=math.ceil(xex_train.shape[0]/FLAGS.batch_size)\n",
    "            \n",
    "            for batch in tqdm(range(total_batch)):\n",
    "                begin=batch*FLAGS.batch_size\n",
    "                end=min(xex_train.shape[0], (batch+1)*FLAGS.batch_size)\n",
    "                batch_x = xex_train[begin:end]\n",
    "                batch_y = yex_train[begin:end]\n",
    "                batch_len = ex_len_train[begin:end]\n",
    "                batch_ind = y_idx_train[begin:end]\n",
    "\n",
    "                [_, train_loss, train_logits] = sess.run([lstm.train_op, lstm.loss_val, lstm.logits],\n",
    "                        feed_dict={lstm.input_x: batch_x, lstm.IND: batch_ind, lstm.s_len: batch_len})\n",
    "\n",
    "            caps_train_loss.append(train_loss)\n",
    "            # training acc.\n",
    "            total_seen_pred_train = np.array([], dtype=np.int64)\n",
    "            \n",
    "            test_batch_pred = np.argmax(logits, 1)\n",
    "            total_seen_pred = np.concatenate((total_seen_pred_train, test_batch_pred))\n",
    "            train_acc = accuracy_score(batch_y, total_seen_pred)\n",
    "            caps_train_acc.append(train_acc)\n",
    "\n",
    "            # validation\n",
    "            \n",
    "            \n",
    "            [val_loss, logits] = sess.run([lstm.loss_val, lstm.logits], \n",
    "                feed_dict={lstm.input_x: xex_test, lstm.IND: y_idx_test, lstm.s_len: ex_len_test})\n",
    "\n",
    "            caps_val_loss.append(val_loss)\n",
    "            \n",
    "            total_seen_pred = np.array([], dtype=np.int64)\n",
    "\n",
    "            print(\"Epoch %d/%d - train loss: %f - val loss: %f\" % (epoch, max(0, FLAGS.num_epochs-1), \n",
    "                                                                   train_loss, val_loss))\n",
    "            \n",
    "            test_batch_pred = np.argmax(logits, 1)\n",
    "            total_seen_pred = np.concatenate((total_seen_pred, test_batch_pred))\n",
    "            val_acc = accuracy_score(yex_test, total_seen_pred)\n",
    "            caps_val_acc.append(val_acc)\n",
    "            \n",
    "            if val_acc > best_caps_acc:\n",
    "                best_caps_acc = val_acc\n",
    "            \n",
    "            print(\"Intent Detection Results [INTENTCAPSNET]\")\n",
    "            print(classification_report(yex_test, total_seen_pred, digits=4))\n",
    "            print(\"Curr CAPS acc: %f - Best CAPS acc: %f\" % (val_acc, best_caps_acc))\n",
    "\n",
    "            #########\n",
    "            em_logits = sess.run(lstm.logits, \n",
    "                feed_dict={lstm.input_x: label_em, lstm.s_len: label_em_len})\n",
    "            data['em_logits']=em_logits/em_logits.sum(axis=1,keepdims=1)\n",
    "            #########\n",
    "\n",
    "            print(\"=================================================================================\")\n",
    "            # check INTENTCAPSNET-ZSL performance\n",
    "            cur_zsl_acc=evaluate_zsl(data, FLAGS, sess)\n",
    "            zsl_acc.append(cur_zsl_acc)\n",
    "            if cur_zsl_acc > best_zsl_acc:\n",
    "                best_zsl_acc = cur_zsl_acc\n",
    "                var_saver.save(sess, os.path.join(FLAGS.ckpt_dir, \"model.ckpt\"), 1) # save model\n",
    "            print(\"Curr ZSL acc: %f - Best ZSL acc: %f\" % (cur_zsl_acc, best_zsl_acc))\n",
    "            \n",
    "            if epoch % 50 ==0:\n",
    "                timelist=[range(0,epoch)]\n",
    "#                 caps_train_loss=[]\n",
    "#                 caps_train_acc=[]\n",
    "    \n",
    "#                 caps_val_loss=[]\n",
    "#                 caps_val_acc=[]\n",
    "                plt.plot(timelist, caps_train_loss)\n",
    "                plt.plot(timelist, caps_val_loss)\n",
    "                plt.xlabel('epoch')\n",
    "                plt.ylabel('training loss')\n",
    "                plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "                os.mkdir('./graphs/')\n",
    "                plt.savefig('./graphs/train_val_loss_%d' % epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
